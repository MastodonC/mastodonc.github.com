---
layout: post
title: Plumbing in big pipes for bigger data with Spark
date: 2016-09-03 12:00
author: fran
comments: true
categories: [engineering, spark, hadoop]
---
In modern enterprises, there is an exciting amount of data available,
which our clients want to put to work for them. Before that can
happen, the data needs to be piped into usable forms and usable
places. It can arrive in lots of different shapes and sizes, from
internal and external systems, so there is a substantial engineering
challenge to get everything together and flowing smoothly enough for
daily operation.

To handle this common challenge, we have developed our cloud-based
platform and toolkit "Kixi" - this is the system we use to ingest and
manage the particular data flows that our clients need for their
particular businesses. One of the most recent technologies we've added
to this set is Apache Spark, which uses a few tricks to be even faster
and more effective than classic Hadoop in processing big datasets.

## All about RDDs

something about how Spark's RDD innovation helps

## What's next for Spark

something about where it is now and where it's headed - how mature is it?

## Conclusion

We are continually exploring the latest big data technologies and
bringing them into our toolkit, so that we can apply them to our
customers' problems. [Contact us](http://www.mastodonc.com/contact/)
if you'd like to talk about how these technologies might help you, and
[read here] for a longer case study of a big data pipeline service.
